{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_h = img_w = 28             # MNIST images are 28x28\n",
    "img_size_flat = img_h * img_w  # 28x28=784, the total number of pixels\n",
    "n_classes = 10                 # Number of classes, one class per digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(mode='train'):\n",
    "    \"\"\"\n",
    "    Function to (download and) load the MNIST data\n",
    "    :param mode: train or test\n",
    "    :return: images and the corresponding labels\n",
    "    \"\"\"\n",
    "    from tensorflow.examples.tutorials.mnist import input_data\n",
    "    mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "    if mode == 'train':\n",
    "        x_train, y_train, x_valid, y_valid = mnist.train.images, mnist.train.labels, \\\n",
    "                                             mnist.validation.images, mnist.validation.labels\n",
    "        return x_train, y_train, x_valid, y_valid\n",
    "    elif mode == 'test':\n",
    "        x_test, y_test = mnist.test.images, mnist.test.labels\n",
    "    return x_test, y_test\n",
    "\n",
    "\n",
    "def randomize(x, y):\n",
    "    \"\"\" Randomizes the order of data samples and their corresponding labels\"\"\"\n",
    "    permutation = np.random.permutation(y.shape[0])\n",
    "    shuffled_x = x[permutation, :]\n",
    "    shuffled_y = y[permutation]\n",
    "    return shuffled_x, shuffled_y\n",
    "\n",
    "\n",
    "def get_next_batch(x, y, start, end):\n",
    "    x_batch = x[start:end]\n",
    "    y_batch = y[start:end]\n",
    "    return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data\n",
    "x_train, y_train, x_valid, y_valid = load_data(mode='train')\n",
    "print(\"Size of:\")\n",
    "print(\"- Training-set:\\t\\t{}\".format(len(y_train)))\n",
    "print(\"- Validation-set:\\t{}\".format(len(y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('x_train:\\t{}'.format(x_train.shape))\n",
    "print('y_train:\\t{}'.format(y_train.shape))\n",
    "print('x_train:\\t{}'.format(x_valid.shape))\n",
    "print('y_valid:\\t{}'.format(y_valid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid[:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "epochs = 10             # Total number of training epochs\n",
    "batch_size = 100        # Training batch size\n",
    "display_freq = 100      # Frequency of displaying the training results\n",
    "learning_rate = 0.001   # The optimization initial learning rate\n",
    "\n",
    "h1 = 200                # number of nodes in the 1st hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# weight and bais wrappers\n",
    "def weight_variable(name, shape):\n",
    "    \"\"\"\n",
    "    Create a weight variable with appropriate initialization\n",
    "    :param name: weight name\n",
    "    :param shape: weight shape\n",
    "    :return: initialized weight variable\n",
    "    \"\"\"\n",
    "    initer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "    return tf.get_variable('W_' + name,\n",
    "                           dtype=tf.float32,\n",
    "                           shape=shape,\n",
    "                           initializer=initer)\n",
    "\n",
    "\n",
    "def bias_variable(name, shape):\n",
    "    \"\"\"\n",
    "    Create a bias variable with appropriate initialization\n",
    "    :param name: bias variable name\n",
    "    :param shape: bias variable shape\n",
    "    :return: initialized bias variable\n",
    "    \"\"\"\n",
    "    initial = tf.constant(0., shape=shape, dtype=tf.float32)\n",
    "    return tf.get_variable('b_' + name,\n",
    "                           dtype=tf.float32,\n",
    "                           initializer=initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_layer(x, num_units, name, use_relu=True):\n",
    "    \"\"\"\n",
    "    Create a fully-connected layer\n",
    "    :param x: input from previous layer\n",
    "    :param num_units: number of hidden units in the fully-connected layer\n",
    "    :param name: layer name\n",
    "    :param use_relu: boolean to add ReLU non-linearity (or not)\n",
    "    :return: The output array\n",
    "    \"\"\"\n",
    "    in_dim = x.get_shape()[1]\n",
    "    W = weight_variable(name, shape=[in_dim, num_units])\n",
    "    b = bias_variable(name, [num_units])\n",
    "    layer = tf.matmul(x, W)\n",
    "    layer += b\n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(layer)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph for the linear model\n",
    "# Placeholders for inputs (x) and outputs(y)\n",
    "x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='X')\n",
    "y = tf.placeholder(tf.float32, shape=[None, n_classes], name='Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a fully-connected layer with h1 nodes as hidden layer\n",
    "fc1 = fc_layer(x, h1, 'FC1', use_relu=True)\n",
    "# Create a fully-connected layer with n_classes nodes as output layer\n",
    "output_logits = fc_layer(fc1, n_classes, 'OUT', use_relu=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function, optimizer, and accuracy\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=output_logits), name='loss')\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, name='Adam-op').minimize(loss)\n",
    "correct_prediction = tf.equal(tf.argmax(output_logits, 1), tf.argmax(y, 1), name='correct_pred')\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')\n",
    "\n",
    "# Network predictions\n",
    "cls_prediction = tf.argmax(output_logits, axis=1, name='predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the op for initializing all variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create an interactive session (to keep the session in the other cells)\n",
    "sess = tf.InteractiveSession()\n",
    "# Initialize all variables\n",
    "sess.run(init)\n",
    "# Number of training iterations in each epoch\n",
    "num_tr_iter = int(len(y_train) / batch_size)\n",
    "for epoch in range(epochs):\n",
    "    print('Training epoch: {}'.format(epoch + 1))\n",
    "    # Randomly shuffle the training data at the beginning of each epoch \n",
    "    x_train, y_train = randomize(x_train, y_train)\n",
    "    for iteration in range(num_tr_iter):\n",
    "        start = iteration * batch_size\n",
    "        end = (iteration + 1) * batch_size\n",
    "        x_batch, y_batch = get_next_batch(x_train, y_train, start, end)\n",
    "\n",
    "        # Run optimization op (backprop)\n",
    "        feed_dict_batch = {x: x_batch, y: y_batch}\n",
    "        sess.run(optimizer, feed_dict=feed_dict_batch)\n",
    "\n",
    "        if iteration % display_freq == 0:\n",
    "            # Calculate and display the batch loss and accuracy\n",
    "            loss_batch, acc_batch = sess.run([loss, accuracy],\n",
    "                                             feed_dict=feed_dict_batch)\n",
    "\n",
    "            print(\"iter {0:3d}:\\t Loss={1:.2f},\\tTraining Accuracy={2:.01%}\".\n",
    "                  format(iteration, loss_batch, acc_batch))\n",
    "\n",
    "    # Run validation after every epoch\n",
    "    feed_dict_valid = {x: x_valid[:1000], y: y_valid[:1000]}\n",
    "    loss_valid, acc_valid = sess.run([loss, accuracy], feed_dict=feed_dict_valid)\n",
    "    print('---------------------------------------------------------')\n",
    "    print(\"Epoch: {0}, validation loss: {1:.2f}, validation accuracy: {2:.01%}\".\n",
    "          format(epoch + 1, loss_valid, acc_valid))\n",
    "    print('---------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the network after training\n",
    "# Accuracy\n",
    "x_test, y_test = load_data(mode='test')\n",
    "feed_dict_test = {x: x_test[:1000], y: y_test[:1000]}\n",
    "loss_test, acc_test = sess.run([loss, accuracy], feed_dict=feed_dict_test)\n",
    "print('---------------------------------------------------------')\n",
    "print(\"Test loss: {0:.2f}, test accuracy: {1:.01%}\".format(loss_test, acc_test))\n",
    "print('---------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_images(images, cls_true, cls_pred=None, title=None):\n",
    "    \"\"\"\n",
    "    Create figure with 3x3 sub-plots.\n",
    "    :param images: array of images to be plotted, (9, img_h*img_w)\n",
    "    :param cls_true: corresponding true labels (9,)\n",
    "    :param cls_pred: corresponding true labels (9,)\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(9, 9))\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Plot image.\n",
    "        ax.imshow(images[i].reshape(28, 28), cmap='binary')\n",
    "\n",
    "        # Show true and predicted classes.\n",
    "        if cls_pred is None:\n",
    "            ax_title = \"True: {0}\".format(cls_true[i])\n",
    "        else:\n",
    "            ax_title = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n",
    "\n",
    "        ax.set_title(ax_title)\n",
    "\n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    if title:\n",
    "        plt.suptitle(title, size=20)\n",
    "    plt.show(block=False)\n",
    "\n",
    "def plot_example_errors(images, cls_true, cls_pred, title=None):\n",
    "    \"\"\"\n",
    "    Function for plotting examples of images that have been mis-classified\n",
    "    :param images: array of all images, (#imgs, img_h*img_w)\n",
    "    :param cls_true: corresponding true labels, (#imgs,)\n",
    "    :param cls_pred: corresponding predicted labels, (#imgs,)\n",
    "    \"\"\"\n",
    "    # Negate the boolean array.\n",
    "    incorrect = np.logical_not(np.equal(cls_pred, cls_true))\n",
    "\n",
    "    # Get the images from the test-set that have been\n",
    "    # incorrectly classified.\n",
    "    incorrect_images = images[incorrect]\n",
    "\n",
    "    # Get the true and predicted classes for those images.\n",
    "    cls_pred = cls_pred[incorrect]\n",
    "    cls_true = cls_true[incorrect]\n",
    "\n",
    "    # Plot the first 9 images.\n",
    "    plot_images(images=incorrect_images[0:9],\n",
    "                cls_true=cls_true[0:9],\n",
    "                cls_pred=cls_pred[0:9],\n",
    "                title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some of the correct and misclassified examples\n",
    "cls_pred = sess.run(cls_prediction, feed_dict=feed_dict_test)\n",
    "cls_true = np.argmax(y_test[:1000], axis=1)\n",
    "plot_images(x_test, cls_true, cls_pred, title='Correct Examples')\n",
    "plot_example_errors(x_test[:1000], cls_true, cls_pred, title='Misclassified Examples')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
